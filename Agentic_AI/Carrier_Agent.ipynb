{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5d257bc",
   "metadata": {},
   "source": [
    "# Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f227b1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Transcend/DeepLearning/.venv_agentic_ai/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Basic Packages \n",
    "from dotenv import load_dotenv\n",
    "# This package is useful to load the environment variables\n",
    "\n",
    "from openai import OpenAI \n",
    "# Package that provide endpoints to utilize the llms\n",
    "\n",
    "import json # json is the best way to communicate with llm's\n",
    "import os\n",
    "import requests\n",
    "\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr # Open source package for building light weight front end application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08dc7e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usual start to load the environment variables\n",
    "load_dotenv(override = True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3968af7d",
   "metadata": {},
   "source": [
    "# PushOver (Notification SetUp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4650858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the email notifications we are going to use pushover package\n",
    "pushover_user = os.getenv(\"PUSHOVER_USER\")\n",
    "pushover_token = os.getenv(\"PUSHOVER_TOKEN\")\n",
    "pushover_url = \"https://api.pushover.net/1/messages.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42e50e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Push: Hi\n"
     ]
    }
   ],
   "source": [
    "def push(message):\n",
    "    print(f\"Push: {message}\")\n",
    "    payload = {'user':pushover_user, \"token\":pushover_token, \"message\":message}\n",
    "    requests.post(pushover_url, data = payload)\n",
    "\n",
    "# Test Sample\n",
    "push(\"Hi\") # Devices that are registered under pushover will be getting notification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf90b791",
   "metadata": {},
   "source": [
    "# ToolCalls \n",
    "\n",
    "1. Define the function\n",
    "2. Provide the tool definition\n",
    "3. Handle Tool Calls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50d0e43",
   "metadata": {},
   "source": [
    "#### 1. Tool Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "858a4044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_user_details(email, name=\"Name not provided\", notes=\"not provided\"):\n",
    "    \"\"\" \n",
    "        Function Descr: If the user wants to iteractive we ask for their email, name and any notes if he provides\n",
    "        :param: email -> str: user email address\n",
    "               name  -> str: user name\n",
    "               notes -> str: notes provided by the user\n",
    "    \"\"\"\n",
    "    push(f\"Recording interest from {name} with email {email} and notes {notes}\")\n",
    "    return {\"recorded\":\"ok\"}\n",
    "\n",
    "\n",
    "\n",
    "def record_unknown_question(question):\n",
    "    \"\"\"\n",
    "        Function Description: If the user asked for a unknown question we record for that information\n",
    "        :param : question -> str : question asked by the user\n",
    "    \"\"\"\n",
    "    push(f\"Recording {question} that I couldn't answer\")\n",
    "    return {\"recorded\":\"ok\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034da75f",
   "metadata": {},
   "source": [
    "#### 2. Tool Definition\n",
    "\n",
    "LLMs can better understand JSON format for tool calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90eea394",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_user_details_json = {\n",
    "    \"name\": \"record_user_details\",\n",
    "    \"description\": \"Use this tool to record that a user is interested in being in touch and provide an email address\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\":{\n",
    "            \"email\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The email address of this user\"\n",
    "            },\n",
    "            \"name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The name of the user\"\n",
    "            },\n",
    "            \"notes\":{\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Any additional information about the conversation that's worth recording to give context\"\n",
    "            }\n",
    "        },\n",
    "        \"required\":[\"email\",\"name\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee9d071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_unknow_question_json = {\n",
    "    \"name\": \"record_unknown_question\",\n",
    "    \"description\": \"Use this tool to record any question that couldn't be answered as you didn't know the answer\",\n",
    "    \"parameters\":{\n",
    "        \"type\":\"object\",\n",
    "        \"properties\": {\n",
    "        \"question\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The question that couldn't be answered\"\n",
    "        },\n",
    "    },\n",
    "    \"required\": [\"question\"],\n",
    "    \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f5f9ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\"type\": \"function\", \"function\":record_user_details_json},\n",
    "         {\"type\": \"function\", \"function\":record_unknow_question_json}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92658039",
   "metadata": {},
   "source": [
    "####  3. Handle Tool Calls\n",
    "- Now, depends on the use case your llm should pick the tool based on the context/situation it's dealing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b68ad1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_calls(tool_calls):\n",
    "    # :param -> tool_calls : Response generated by LLMs\n",
    "    results = []\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call.function.name\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        print(f\"Tool called: {tool_name}\", flush = True)\n",
    "\n",
    "        # globals() function gets all the functions that are declared in the python environment\n",
    "        tool = globals().get(tool_name)\n",
    "        result = tool(**arguments) if tool else {}\n",
    "        results.append({\"role\": \"tool\", \"content\":json.dumps(result), \"tool_call_id\": tool_call.id})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96558c07",
   "metadata": {},
   "source": [
    "# Linked Profile Context\n",
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92cf7554",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text\n",
    "\n",
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()\n",
    "\n",
    "name = \"Ed Donner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "945fa400",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer to any question, use your record_unknown_question tool to record the question that you couldn't answer, even if it's about something trivial or unrelated to career. \\\n",
    "If the user is engaging in discussion, try to steer them towards getting in touch via email; ask for their email and record it using your record_user_details tool. \"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd3ff2b",
   "metadata": {},
   "source": [
    "# Agentic Workflow LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df619776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{'role':'system', 'content':system_prompt}] + \\\n",
    "                    history + \\\n",
    "            [{\"role\":\"user\", 'content':message}]\n",
    "    done = False\n",
    "    while not done:\n",
    "\n",
    "        # This is the call to the LLM - see that we pass in the tools json\n",
    "\n",
    "        response = openai.chat.completions.create(model = \"gpt-4o-mini\", messages=messages, \n",
    "                                                  tools = tools)\n",
    "        print(response)\n",
    "        finish_reason = response.choices[0].finish_reason\n",
    "\n",
    "        # If the LLM wants to call a tool, we do that!\n",
    "        if finish_reason == \"tool_calls\":\n",
    "            message = response.choices[0].message\n",
    "            tool_calls = message.tool_calls\n",
    "            results = handle_tool_calls(tool_calls)\n",
    "            messages.append(message)\n",
    "            messages.extend(results)\n",
    "        else:\n",
    "            done = True\n",
    "        \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e58f3f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-BY3rwlEuOpSWs1NXxvX7qFFZc7QMK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! Thank you for visiting my website. How can I assist you today?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1747457724, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_96c46af214', usage=CompletionUsage(completion_tokens=17, prompt_tokens=2363, total_tokens=2380, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=2048)))\n",
      "ChatCompletion(id='chatcmpl-BY3s6m3yx91fJIgaCQXotlW8Gf04t', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"That's great to hear! I'd love to connect. Could you please share your email address so we can stay in touch?\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1747457734, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_96c46af214', usage=CompletionUsage(completion_tokens=25, prompt_tokens=2394, total_tokens=2419, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=2304)))\n",
      "ChatCompletion(id='chatcmpl-BY3sFxRMpUDXrvoFQDlJVmmQW3ALN', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_qWsOsJNUqlwbOiyAdqS19gUC', function=Function(arguments='{\"email\":\"vinayak@gmail.com\",\"name\":\"Vinayak\",\"notes\":\"User expressed interest in connecting.\"}', name='record_user_details'), type='function')]))], created=1747457743, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_96c46af214', usage=CompletionUsage(completion_tokens=34, prompt_tokens=2431, total_tokens=2465, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=2304)))\n",
      "Tool called: record_user_details\n",
      "Push: Recording interest from Vinayak with email vinayak@gmail.com and notes User expressed interest in connecting.\n",
      "ChatCompletion(id='chatcmpl-BY3sJxE6OSPFWucK2bSHhptmQxYHu', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Thank you, Vinayak! I've noted down your email address, and I'm looking forward to connecting with you. If you have any specific questions or topics you'd like to discuss, feel free to let me know!\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1747457747, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_96c46af214', usage=CompletionUsage(completion_tokens=44, prompt_tokens=2481, total_tokens=2525, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=2432)))\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type = \"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9cab84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_agentic_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
